{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands on Practical Deep learning with PyTorch\n",
    "### Sign Language Digits Dataset\n",
    "https://www.kaggle.com/ankitjha/hands-on-practical-deep-learning-with-pytorch/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T23:18:52.968062Z",
     "start_time": "2019-03-23T23:18:52.849048Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T23:18:53.944045Z",
     "start_time": "2019-03-23T23:18:53.770679Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T23:25:33.122125Z",
     "start_time": "2019-03-23T23:25:33.087890Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.load('./data/X.npy')*255\n",
    "target = np.load('./data/Y.npy')\n",
    "Y = np.zeros(data.shape[0])\n",
    "Y[:204] = 9\n",
    "Y[204:409] = 0\n",
    "Y[409:615] = 7\n",
    "Y[615:822] = 6\n",
    "Y[822:1028] = 1\n",
    "Y[1028:1236] = 8\n",
    "Y[1236:1443] = 4\n",
    "Y[1443:1649] = 3\n",
    "Y[1649:1855] = 2\n",
    "Y[1855:] = 5\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, Y, test_size = .02, random_state = 2) \n",
    "## splitting into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T23:25:34.517483Z",
     "start_time": "2019-03-23T23:25:34.501932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2020, 64, 64), 255.0, 1.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train.max(), X_train.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Data must be wrapped on a Dataset parent class where the methods getitem and len must be overrided. Not that, the data is not loaded on memory by now.\n",
    "- The Dataloader reads the data and puts it into memory.\n",
    "\n",
    "- torchvision - It is used to load and prepare dataset. Using it you can create transformations on the input data. \n",
    "\n",
    "- transforms - It is used for preprocessing images and performing operations sequentially. \n",
    "\n",
    "- num_workers - It is used for multiprocessing.Normally, num_workers = 4 * (number of gpus) works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T23:25:52.192843Z",
     "start_time": "2019-03-23T23:25:52.180525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2020, 64, 64)\n",
      "(1, 64, 64)\n",
      "(1, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "x = X_train[77:78,...]\n",
    "print(x.shape)\n",
    "x = x.reshape((-1, 64, 64)).astype(np.uint8)[:, :, :, None]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T23:21:30.148264Z",
     "start_time": "2019-03-23T23:21:30.134098Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class DatasetProcessing(Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        # used to initialise the class variables - transform, data, target\n",
    "        self.transform = transform\n",
    "        # print(data.shape)\n",
    "        self.data = torch.from_numpy(data.reshape((-1, 64, 64))[:, None, :, :])\n",
    "        # print(self.data.shape)\n",
    "        self.target = torch.from_numpy(target).long()\n",
    "        # needs to be in torch.LongTensor dtype\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # used to retrieve the X and y index value and return it\n",
    "        return self.transform(self.data[index]), self.target[index]\n",
    "#         return self.data[index], self.target[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # returns the length of the data\n",
    "        return len(list(self.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T23:21:30.482849Z",
     "start_time": "2019-03-23T23:21:30.466106Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "dset_train = DatasetProcessing(X_train, y_train, transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dset_train, batch_size=2020, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T23:23:52.499183Z",
     "start_time": "2019-03-23T23:23:52.375729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003921569 1.0\n",
      "torch.Size([2020, 1, 64, 64]) torch.Size([2020])\n",
      "-0.9921568632125854 1.0\n"
     ]
    }
   ],
   "source": [
    "# print(X_train.shape, y_train.shape)\n",
    "print(\n",
    "      np.min(X_train), \n",
    "      np.max(X_train),\n",
    "#       np.min(y_train),\n",
    "#       np.max(y_train),\n",
    "     )\n",
    "xx, yy = next(iter(train_loader))\n",
    "print(xx.shape, yy.shape)\n",
    "print(\n",
    "      torch.min(xx),\n",
    "      torch.max(xx),\n",
    "#       torch.min(yy), \n",
    "#       torch.max(yy),\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T23:23:52.997329Z",
     "start_time": "2019-03-23T23:23:52.983975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2020, 1, 64, 64]), torch.Size([1, 64, 64]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= torch.from_numpy(X_train.reshape((-1, 64, 64))[:, None, :, :])\n",
    "data.shape, data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T23:24:17.785147Z",
     "start_time": "2019-03-23T23:24:17.767474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  122  125  130  ...   115  114  111\n",
       "  124  128  132  ...   116  114  112\n",
       "  125  129  134  ...   117  115  112\n",
       "      ...         â‹±        ...      \n",
       "  115  117  120  ...   112  109  107\n",
       "  113  116  118  ...   111  109  107\n",
       "  110  113  115  ...   110  108  105\n",
       "[torch.FloatTensor of size 1x64x64]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T23:11:43.973518Z",
     "start_time": "2019-03-23T23:11:43.956542Z"
    }
   },
   "outputs": [],
   "source": [
    "results = transforms.ToPILImage()(X_train.reshape((-1, 64, 64)).astype(np.uint8)[:, :, :, None][1])\n",
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T23:11:01.699257Z",
     "start_time": "2019-03-23T23:11:01.684433Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "print(xx.shape)\n",
    "nn.Sequential(nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1))(Variable(xx)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T22:46:41.959052Z",
     "start_time": "2019-03-23T22:46:41.920768Z"
    }
   },
   "outputs": [],
   "source": [
    "dset_test = DatasetProcessing(X_test, y_test, transform)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dset_test, batch_size=4, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T23:11:06.976548Z",
     "start_time": "2019-03-23T23:11:06.779166Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for num, x in enumerate(X_train[0:6]):\n",
    "    plt.subplot(1,6,num+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x)\n",
    "    plt.title(y_train[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T10:47:26.284821Z",
     "start_time": "2019-03-23T10:47:26.269973Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(32 * 32 * 32, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T10:47:28.361601Z",
     "start_time": "2019-03-23T10:47:26.682099Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "model = Net()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Cuda!')\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T10:47:31.802471Z",
     "start_time": "2019-03-23T10:47:31.758768Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    exp_lr_scheduler.step()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        #print(data.size())\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        #print(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
    "                100. * (batch_idx + 1) / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T10:47:49.392152Z",
     "start_time": "2019-03-23T10:47:49.378110Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def evaluate(data_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for data, target in data_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "        loss += F.cross_entropy(output, target, size_average=False).data[0]\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    loss /= len(data_loader.dataset)\n",
    "\n",
    "    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T10:47:58.148272Z",
     "start_time": "2019-03-23T10:47:50.060036Z"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 2\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch)\n",
    "    evaluate(train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
